{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 25)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, auc, roc_auc_score, cohen_kappa_score, confusion_matrix\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm import tqdm_notebook\n",
    "import time\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>age</th>\n",
       "      <th>new_user</th>\n",
       "      <th>source</th>\n",
       "      <th>total_pages_visited</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UK</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>Ads</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>Seo</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>Seo</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>China</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>Seo</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>Seo</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  age  new_user source  total_pages_visited  converted\n",
       "0      UK   25         1    Ads                    1          0\n",
       "1      US   23         1    Seo                    5          0\n",
       "2      US   28         1    Seo                    4          0\n",
       "3   China   39         1    Seo                    5          0\n",
       "4      US   30         1    Seo                    6          0"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('conversion_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>age</th>\n",
       "      <th>new_user</th>\n",
       "      <th>source</th>\n",
       "      <th>total_pages_visited</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  age  new_user  source  total_pages_visited  converted\n",
       "0        2   25         1       0                    1          0\n",
       "1        3   23         1       2                    5          0\n",
       "2        3   28         1       2                    4          0\n",
       "3        0   39         1       2                    5          0\n",
       "4        3   30         1       2                    6          0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def str_encode(data, encoder_dict=None):\n",
    "    '''\n",
    "    convert string variables to int, no one-hot-encode\n",
    "    If used first time, initiate encoder_dict, else user can specify encoder_dict\n",
    "    '''\n",
    "    res = data.copy()\n",
    "    if encoder_dict is None:\n",
    "        encoder_dict = {}\n",
    "        for col in data.columns:\n",
    "            if data[col].dtype == 'object': #if typeof(col) == 'object'\n",
    "                str_dict = dict(zip(np.unique(data[col]), range(len(np.unique(data[col])))))\n",
    "                res[col] = data[col].map(str_dict)\n",
    "                encoder_dict[col] = str_dict\n",
    "        return res, encoder_dict\n",
    "    else:\n",
    "        for col in data.columns:\n",
    "            if data[col].dtype == 'object':\n",
    "                str_dict = encoder_dict[col]\n",
    "                res[col] = data[col].map(str_dict)\n",
    "        return res\n",
    "\n",
    "def str_onehotencode(data, encoder_dict=None):\n",
    "    '''convert string variables to one-hot-encode'''\n",
    "    res = data.copy()\n",
    "    encoder_dict = None\n",
    "    if encoder_dict is None:\n",
    "        encoder_dict = {}\n",
    "        for col in data.columns:\n",
    "            if data[col].dtype == 'object':\n",
    "                str_dict = dict(zip(np.unique(data[col]), range(len(np.unique(data[col])))))\n",
    "                for i in list(str_dict.keys()):\n",
    "                    res[f'{col}_{str_dict[i]}'] = (data[col] == i).astype(int)\n",
    "                encoder_dict[col] = str_dict\n",
    "                res = res.drop([col],1)\n",
    "        return res, encoder_dict\n",
    "    else:\n",
    "        for col in data.columns:\n",
    "            if data[col].dtype == 'object':\n",
    "                str_dict = encoder_dict[col]\n",
    "                for i in list(str_dict.keys()):\n",
    "                    res[f'{col}_{str_dict[i]}'] = (data[col] == i).astype(int)\n",
    "                res = res.drop([col],1)\n",
    "        return res\n",
    "        \n",
    "df_e, encoder_dict = str_encode(data)\n",
    "df_e.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>new_user</th>\n",
       "      <th>total_pages_visited</th>\n",
       "      <th>converted</th>\n",
       "      <th>country_0</th>\n",
       "      <th>country_1</th>\n",
       "      <th>country_2</th>\n",
       "      <th>country_3</th>\n",
       "      <th>source_0</th>\n",
       "      <th>source_1</th>\n",
       "      <th>source_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  new_user  total_pages_visited  converted  country_0  country_1  \\\n",
       "0   25         1                    1          0          0          0   \n",
       "1   23         1                    5          0          0          0   \n",
       "2   28         1                    4          0          0          0   \n",
       "3   39         1                    5          0          1          0   \n",
       "4   30         1                    6          0          0          0   \n",
       "\n",
       "   country_2  country_3  source_0  source_1  source_2  \n",
       "0          1          0         1         0         0  \n",
       "1          0          1         0         0         1  \n",
       "2          0          1         0         0         1  \n",
       "3          0          0         0         0         1  \n",
       "4          0          1         0         0         1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ohe, encoder_dict = str_onehotencode(data)\n",
    "df_ohe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'country': {'China': 0, 'Germany': 1, 'UK': 2, 'US': 3},\n",
       " 'source': {'Ads': 0, 'Direct': 1, 'Seo': 2}}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-linearity?\n",
    "    if you need to remove co-linear features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x129364668>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr = df_e.corr()\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0, annot=True,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas data aggregation\n",
    "    say you want to know what's the mean/min/max age, proportion of new users, proportion of source, mean/min/max total_pages_visited, mean converted of users from different country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>age</th>\n",
       "      <th>new_user</th>\n",
       "      <th>source</th>\n",
       "      <th>total_pages_visited</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  age  new_user  source  total_pages_visited  converted\n",
       "0        2   25         1       0                    1          0\n",
       "1        3   23         1       2                    5          0\n",
       "2        3   28         1       2                    4          0\n",
       "3        0   39         1       2                    5          0\n",
       "4        3   30         1       2                    6          0"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_e.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">age</th>\n",
       "      <th>new_user</th>\n",
       "      <th colspan=\"3\" halign=\"left\">source</th>\n",
       "      <th colspan=\"6\" halign=\"left\">total_pages_visited</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>Range</th>\n",
       "      <th>mean</th>\n",
       "      <th>ratio_of_zero</th>\n",
       "      <th>ratio_of_one</th>\n",
       "      <th>ratio_of_two</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>Range</th>\n",
       "      <th>iqr</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.672972</td>\n",
       "      <td>17</td>\n",
       "      <td>69</td>\n",
       "      <td>8.283862</td>\n",
       "      <td>52</td>\n",
       "      <td>0.698520</td>\n",
       "      <td>0.281468</td>\n",
       "      <td>0.227971</td>\n",
       "      <td>0.490562</td>\n",
       "      <td>4.553523</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>2.804987</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.449985</td>\n",
       "      <td>17</td>\n",
       "      <td>123</td>\n",
       "      <td>8.289022</td>\n",
       "      <td>106</td>\n",
       "      <td>0.677237</td>\n",
       "      <td>0.287990</td>\n",
       "      <td>0.219363</td>\n",
       "      <td>0.492647</td>\n",
       "      <td>5.190717</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>3.762899</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>0.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.451538</td>\n",
       "      <td>17</td>\n",
       "      <td>111</td>\n",
       "      <td>8.244991</td>\n",
       "      <td>94</td>\n",
       "      <td>0.679835</td>\n",
       "      <td>0.279009</td>\n",
       "      <td>0.229742</td>\n",
       "      <td>0.491249</td>\n",
       "      <td>5.082167</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>3.630763</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>0.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.566482</td>\n",
       "      <td>17</td>\n",
       "      <td>79</td>\n",
       "      <td>8.272128</td>\n",
       "      <td>62</td>\n",
       "      <td>0.681985</td>\n",
       "      <td>0.280198</td>\n",
       "      <td>0.230005</td>\n",
       "      <td>0.489797</td>\n",
       "      <td>4.930160</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>3.427085</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>0.037801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age                           new_user        source  \\\n",
       "              mean min  max       std Range      mean ratio_of_zero   \n",
       "country                                                               \n",
       "0        30.672972  17   69  8.283862    52  0.698520      0.281468   \n",
       "1        30.449985  17  123  8.289022   106  0.677237      0.287990   \n",
       "2        30.451538  17  111  8.244991    94  0.679835      0.279009   \n",
       "3        30.566482  17   79  8.272128    62  0.681985      0.280198   \n",
       "\n",
       "                                  total_pages_visited                          \\\n",
       "        ratio_of_one ratio_of_two                mean min max       std Range   \n",
       "country                                                                         \n",
       "0           0.227971     0.490562            4.553523   1  26  2.804987    25   \n",
       "1           0.219363     0.492647            5.190717   1  27  3.762899    26   \n",
       "2           0.229742     0.491249            5.082167   1  27  3.630763    26   \n",
       "3           0.230005     0.489797            4.930160   1  29  3.427085    28   \n",
       "\n",
       "            converted  \n",
       "        iqr      mean  \n",
       "country                \n",
       "0         4  0.001332  \n",
       "1         5  0.062500  \n",
       "2         5  0.052632  \n",
       "3         5  0.037801  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Range(x):\n",
    "    return np.max(x) - np.min(x)\n",
    "def ratio_of_zero(x):\n",
    "    return len(x[x==0])/len(x)\n",
    "def ratio_of_one(x):\n",
    "    return len(x[x==1])/len(x)\n",
    "def ratio_of_two(x):\n",
    "    return len(x[x==2])/len(x)\n",
    "def iqr(x):\n",
    "    return np.percentile(x,75) - np.percentile(x,25)\n",
    "\n",
    "agg_dict = {'age': ['mean','min','max',np.std, Range],\n",
    "            'new_user': ['mean'],\n",
    "            'source': [ratio_of_zero,ratio_of_one,ratio_of_two],\n",
    "            'total_pages_visited': ['mean','min','max',np.std, Range,iqr],\n",
    "            'converted':['mean']\n",
    "           }\n",
    "\n",
    "df_agg = df_e.groupby('country').agg(agg_dict)\n",
    "df_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_mean</th>\n",
       "      <th>age_min</th>\n",
       "      <th>age_max</th>\n",
       "      <th>age_std</th>\n",
       "      <th>age_Range</th>\n",
       "      <th>new_user_mean</th>\n",
       "      <th>source_ratio_of_zero</th>\n",
       "      <th>source_ratio_of_one</th>\n",
       "      <th>source_ratio_of_two</th>\n",
       "      <th>total_pages_visited_mean</th>\n",
       "      <th>total_pages_visited_min</th>\n",
       "      <th>total_pages_visited_max</th>\n",
       "      <th>total_pages_visited_std</th>\n",
       "      <th>total_pages_visited_Range</th>\n",
       "      <th>total_pages_visited_iqr</th>\n",
       "      <th>converted_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.672972</td>\n",
       "      <td>17</td>\n",
       "      <td>69</td>\n",
       "      <td>8.283862</td>\n",
       "      <td>52</td>\n",
       "      <td>0.698520</td>\n",
       "      <td>0.281468</td>\n",
       "      <td>0.227971</td>\n",
       "      <td>0.490562</td>\n",
       "      <td>4.553523</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>2.804987</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.449985</td>\n",
       "      <td>17</td>\n",
       "      <td>123</td>\n",
       "      <td>8.289022</td>\n",
       "      <td>106</td>\n",
       "      <td>0.677237</td>\n",
       "      <td>0.287990</td>\n",
       "      <td>0.219363</td>\n",
       "      <td>0.492647</td>\n",
       "      <td>5.190717</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>3.762899</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>0.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.451538</td>\n",
       "      <td>17</td>\n",
       "      <td>111</td>\n",
       "      <td>8.244991</td>\n",
       "      <td>94</td>\n",
       "      <td>0.679835</td>\n",
       "      <td>0.279009</td>\n",
       "      <td>0.229742</td>\n",
       "      <td>0.491249</td>\n",
       "      <td>5.082167</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>3.630763</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>0.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.566482</td>\n",
       "      <td>17</td>\n",
       "      <td>79</td>\n",
       "      <td>8.272128</td>\n",
       "      <td>62</td>\n",
       "      <td>0.681985</td>\n",
       "      <td>0.280198</td>\n",
       "      <td>0.230005</td>\n",
       "      <td>0.489797</td>\n",
       "      <td>4.930160</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>3.427085</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>0.037801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          age_mean  age_min  age_max   age_std  age_Range  new_user_mean  \\\n",
       "country                                                                    \n",
       "0        30.672972       17       69  8.283862         52       0.698520   \n",
       "1        30.449985       17      123  8.289022        106       0.677237   \n",
       "2        30.451538       17      111  8.244991         94       0.679835   \n",
       "3        30.566482       17       79  8.272128         62       0.681985   \n",
       "\n",
       "         source_ratio_of_zero  source_ratio_of_one  source_ratio_of_two  \\\n",
       "country                                                                   \n",
       "0                    0.281468             0.227971             0.490562   \n",
       "1                    0.287990             0.219363             0.492647   \n",
       "2                    0.279009             0.229742             0.491249   \n",
       "3                    0.280198             0.230005             0.489797   \n",
       "\n",
       "         total_pages_visited_mean  total_pages_visited_min  \\\n",
       "country                                                      \n",
       "0                        4.553523                        1   \n",
       "1                        5.190717                        1   \n",
       "2                        5.082167                        1   \n",
       "3                        4.930160                        1   \n",
       "\n",
       "         total_pages_visited_max  total_pages_visited_std  \\\n",
       "country                                                     \n",
       "0                             26                 2.804987   \n",
       "1                             27                 3.762899   \n",
       "2                             27                 3.630763   \n",
       "3                             29                 3.427085   \n",
       "\n",
       "         total_pages_visited_Range  total_pages_visited_iqr  converted_mean  \n",
       "country                                                                      \n",
       "0                               25                        4        0.001332  \n",
       "1                               26                        5        0.062500  \n",
       "2                               26                        5        0.052632  \n",
       "3                               28                        5        0.037801  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg.columns = [\"_\".join(x) for x in df_agg.columns.ravel()] \n",
    "#df_agg = df_agg.reset_index()\n",
    "df_agg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFold pipeline\n",
    "    works for all sklearn models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression, RidgeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "\n",
    "def KFold_sklearn(df, clf, n_splits=5, target='converted', name='RandomForestClassifier'):\n",
    "    #print('Number of features = {}'.format(df.shape[1]-1))\n",
    "    start_time = time.time()\n",
    "    folds = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    oof = np.zeros(len(df))\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(df, df[target].round())):    \n",
    "                \n",
    "        x_trn, y_trn = df.drop([target],axis=1).iloc[trn_idx], df[target].iloc[trn_idx]\n",
    "        x_val, y_val = df.drop([target],axis=1).iloc[val_idx], df[target].iloc[val_idx]\n",
    "        \n",
    "        clf.fit(x_trn, y_trn)\n",
    "        preds = clf.predict(x_val)\n",
    "        oof[val_idx] = preds\n",
    "        \n",
    "        ACC = accuracy_score(df[target].iloc[val_idx], oof[val_idx]).round(3)\n",
    "        REC = recall_score(df[target].iloc[val_idx], oof[val_idx]).round(3)\n",
    "        PRE = precision_score(df[target].iloc[val_idx], oof[val_idx]).round(3)\n",
    "        AUC = roc_auc_score(df[target].iloc[val_idx], oof[val_idx]).round(3)\n",
    "        KAP = cohen_kappa_score(df[target].iloc[val_idx], oof[val_idx]).round(3)\n",
    "        F1  = f1_score(df[target].iloc[val_idx], oof[val_idx]).round(3)\n",
    "        #print(f'fold {fold_}: \\naccuracy score: {ACC}   recall: {REC}   precision: {PRE}   AUC: {AUC}    kappa: {KAP}   F1: {F1}')\n",
    "    \n",
    "    ACC = accuracy_score(df[target], oof).round(3)\n",
    "    REC = recall_score(df[target], oof).round(3)\n",
    "    PRE = precision_score(df[target], oof).round(3)\n",
    "    AUC = roc_auc_score(df[target], oof).round(3)\n",
    "    KAP = cohen_kappa_score(df[target], oof).round(3)\n",
    "    F1  = f1_score(df[target], oof).round(3)\n",
    "    \n",
    "    print(f'{ACC}\\t\\t{REC}\\t{PRE}\\t\\t{AUC}\\t{F1}\\t{round(time.time() - start_time,0)}\\t\\t{name}')\n",
    "    #print('Confusion matrix:')\n",
    "    #print(confusion_matrix(df[target], oof))\n",
    "    return oof\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MLPClassifier',\n",
       " 'AdaBoostClassifier',\n",
       " 'RandomForestClassifier',\n",
       " 'DecisionTreeClassifier',\n",
       " 'LogisticRegression',\n",
       " 'QuadraticDiscriminantAnalysis',\n",
       " 'GaussianNB',\n",
       " 'KNeighborsClassifier',\n",
       " 'BaggingClassifier',\n",
       " 'ExtraTreesClassifier',\n",
       " 'SGDClassifier',\n",
       " 'LinearSVC']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_list = [\n",
    "    MLPClassifier(**{'random_state':0}),\n",
    "    AdaBoostClassifier(**{'n_estimators':100,'random_state':0}),\n",
    "    RandomForestClassifier(**{'random_state':0, 'n_estimators':100, 'n_jobs':-1, 'max_depth':10}),\n",
    "    DecisionTreeClassifier(**{'random_state':0, 'max_depth':10}),\n",
    "    LogisticRegression(**{'random_state':0, 'C':2}),\n",
    "    QuadraticDiscriminantAnalysis(**{}),\n",
    "    GaussianNB(**{}),\n",
    "    KNeighborsClassifier(**{'n_jobs':-1}),\n",
    "    BaggingClassifier(**{'random_state':0, 'n_jobs':-1}),\n",
    "    ExtraTreesClassifier(**{'random_state':0, 'n_jobs':-1}),\n",
    "    SGDClassifier(**{'random_state':0, 'n_jobs':-1}),\n",
    "    LinearSVC(**{'random_state':0}),\n",
    "]\n",
    "\n",
    "name_list = [*map(lambda t:str(t.__class__).split('.')[-1].strip(\"'>\"), clf_list)]\n",
    "name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scale\n",
    "scaler = StandardScaler()\n",
    "df_ohe_scaled = pd.DataFrame(scaler.fit_transform(df_ohe.drop(['converted'],1)))\n",
    "df_ohe_scaled['converted'] = df_ohe['converted']\n",
    "df_ohe_scaled.columns = df_ohe.columns\n",
    "df_ohe_scaled['converted'] = (df_ohe_scaled['converted']).astype(int)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_e_scaled = pd.DataFrame(scaler.fit_transform(df_e.drop(['converted'],1)))\n",
    "df_e_scaled['converted'] = df_e['converted']\n",
    "df_e_scaled.columns = df_e.columns\n",
    "df_e_scaled['converted'] = (df_e_scaled['converted']).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\tRecall\tPrecision\tAUC\tF1\tTime(s)\t\tModel\n",
      "0.986\t\t0.662\t0.87\t\t0.829\t0.752\t158.0\t\tMLPClassifier\n",
      "0.986\t\t0.685\t0.853\t\t0.841\t0.76\t42.0\t\tAdaBoostClassifier\n",
      "0.986\t\t0.683\t0.845\t\t0.839\t0.756\t23.0\t\tRandomForestClassifier\n",
      "0.986\t\t0.679\t0.842\t\t0.837\t0.752\t4.0\t\tDecisionTreeClassifier\n",
      "0.986\t\t0.689\t0.855\t\t0.842\t0.763\t5.0\t\tLogisticRegression\n",
      "0.921\t\t0.806\t0.264\t\t0.866\t0.398\t3.0\t\tQuadraticDiscriminantAnalysis\n",
      "0.964\t\t0.845\t0.471\t\t0.907\t0.605\t3.0\t\tGaussianNB\n",
      "0.985\t\t0.669\t0.82\t\t0.832\t0.737\t27.0\t\tKNeighborsClassifier\n",
      "0.984\t\t0.669\t0.81\t\t0.832\t0.733\t23.0\t\tBaggingClassifier\n",
      "0.984\t\t0.649\t0.828\t\t0.822\t0.728\t5.0\t\tExtraTreesClassifier\n",
      "0.983\t\t0.728\t0.741\t\t0.86\t0.735\t14.0\t\tSGDClassifier\n",
      "0.984\t\t0.662\t0.819\t\t0.829\t0.732\t128.0\t\tLinearSVC\n"
     ]
    }
   ],
   "source": [
    "oof_list_ohe = []\n",
    "print('Accuracy\\tRecall\\tPrecision\\tAUC\\tF1\\tTime(s)\\t\\tModel')\n",
    "for i in range(len(clf_list)):\n",
    "    oof = KFold_sklearn(df_ohe, clf_list[i], name=name_list[i])\n",
    "    oof_list_ohe.append(oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\tRecall\tPrecision\tAUC\tF1\tTime(s)\t\tModel\n",
      "0.986\t\t0.701\t0.835\t\t0.848\t0.762\t112.0\t\tMLPClassifier\n",
      "0.986\t\t0.685\t0.853\t\t0.84\t0.76\t36.0\t\tAdaBoostClassifier\n",
      "0.986\t\t0.686\t0.847\t\t0.841\t0.758\t21.0\t\tRandomForestClassifier\n",
      "0.986\t\t0.68\t0.842\t\t0.838\t0.753\t3.0\t\tDecisionTreeClassifier\n",
      "0.986\t\t0.671\t0.849\t\t0.834\t0.75\t5.0\t\tLogisticRegression\n",
      "0.983\t\t0.768\t0.728\t\t0.879\t0.747\t3.0\t\tQuadraticDiscriminantAnalysis\n",
      "0.983\t\t0.768\t0.727\t\t0.879\t0.747\t3.0\t\tGaussianNB\n",
      "0.985\t\t0.671\t0.818\t\t0.833\t0.737\t20.0\t\tKNeighborsClassifier\n",
      "0.984\t\t0.67\t0.81\t\t0.832\t0.733\t21.0\t\tBaggingClassifier\n",
      "0.984\t\t0.65\t0.827\t\t0.822\t0.728\t5.0\t\tExtraTreesClassifier\n",
      "0.983\t\t0.665\t0.783\t\t0.83\t0.719\t12.0\t\tSGDClassifier\n",
      "0.984\t\t0.61\t0.845\t\t0.803\t0.708\t131.0\t\tLinearSVC\n"
     ]
    }
   ],
   "source": [
    "oof_list_e = []\n",
    "print('Accuracy\\tRecall\\tPrecision\\tAUC\\tF1\\tTime(s)\\t\\tModel')\n",
    "for i in range(len(clf_list)):\n",
    "    oof = KFold_sklearn(df_e, clf_list[i], name=name_list[i])\n",
    "    oof_list_e.append(oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\tRecall\tPrecision\tAUC\tF1\tTime(s)\t\tModel\n",
      "0.986\t\t0.701\t0.833\t\t0.848\t0.761\t56.0\t\tMLPClassifier\n",
      "0.986\t\t0.685\t0.853\t\t0.84\t0.76\t35.0\t\tAdaBoostClassifier\n",
      "0.986\t\t0.686\t0.847\t\t0.841\t0.758\t21.0\t\tRandomForestClassifier\n",
      "0.986\t\t0.68\t0.842\t\t0.838\t0.752\t3.0\t\tDecisionTreeClassifier\n",
      "0.986\t\t0.671\t0.849\t\t0.833\t0.749\t4.0\t\tLogisticRegression\n",
      "0.983\t\t0.768\t0.728\t\t0.879\t0.747\t3.0\t\tQuadraticDiscriminantAnalysis\n",
      "0.983\t\t0.768\t0.727\t\t0.879\t0.747\t3.0\t\tGaussianNB\n",
      "0.984\t\t0.676\t0.807\t\t0.835\t0.736\t25.0\t\tKNeighborsClassifier\n",
      "0.984\t\t0.669\t0.81\t\t0.832\t0.733\t21.0\t\tBaggingClassifier\n",
      "0.984\t\t0.65\t0.827\t\t0.823\t0.728\t5.0\t\tExtraTreesClassifier\n",
      "0.985\t\t0.663\t0.85\t\t0.83\t0.745\t4.0\t\tSGDClassifier\n",
      "0.985\t\t0.65\t0.865\t\t0.823\t0.742\t25.0\t\tLinearSVC\n"
     ]
    }
   ],
   "source": [
    "oof_list_e_scaled = []\n",
    "print('Accuracy\\tRecall\\tPrecision\\tAUC\\tF1\\tTime(s)\\t\\tModel')\n",
    "for i in range(len(clf_list)):\n",
    "    oof = KFold_sklearn(df_e_scaled, clf_list[i], name=name_list[i])\n",
    "    oof_list_e_scaled.append(oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KFold_lgb(df, param, categorial_features, n_splits=5, target='converted'):\n",
    "\n",
    "    print('Number of features = {}'.format(df.shape[1]-1))\n",
    "\n",
    "    folds = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    oof = np.zeros(len(df))\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(df, df[target].round())):\n",
    "        print(\"fold {}\".format(fold_))\n",
    "        trn_data = lgb.Dataset(df.drop([target],axis=1).iloc[trn_idx], label=df[target].iloc[trn_idx],\n",
    "                               categorical_feature=categorial_features\n",
    "                              )\n",
    "        val_data = lgb.Dataset(df.drop([target],axis=1).iloc[val_idx], label=df[target].iloc[val_idx],\n",
    "                               categorical_feature=categorial_features\n",
    "                              )\n",
    "        num_round = 10000\n",
    "        clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds=1000)\n",
    "        preds = clf.predict(df.drop([target],axis=1).iloc[val_idx], num_iteration=clf.best_iteration)\n",
    "        oof[val_idx] = preds.round()\n",
    "        \n",
    "    ACC = accuracy_score(df[target], oof).round(3)\n",
    "    REC = recall_score(df[target], oof).round(3)\n",
    "    PRE = precision_score(df[target], oof).round(3)\n",
    "    AUC = roc_auc_score(df[target], oof).round(3)\n",
    "    F1  = f1_score(df[target], oof).round(3)\n",
    "    \n",
    "    print(f'Final result: \\naccuracy score: {ACC}   recall: {REC}   precision: {PRE}   AUC: {AUC}  F1: {F1}')\n",
    "    #print('Confusion matrix:')\n",
    "    #print(confusion_matrix(df[target], oof))\n",
    "    return oof\n",
    "\n",
    "param = {'feature_fraction':0.95, 'reg_alpha': 10, 'reg_lambda':10, \n",
    "         'objective':'binary', 'metric':'binary', 'boosting':'gbdt',\n",
    "         'seed':42, 'bagging_seed':42, 'feature_fraction_seed':42,\n",
    "         'n_jobs':-1\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features = 5\n",
      "fold 0\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's binary_logloss: 0.0399257\tvalid_1's binary_logloss: 0.0419985\n",
      "Early stopping, best iteration is:\n",
      "[399]\ttraining's binary_logloss: 0.0399257\tvalid_1's binary_logloss: 0.0419985\n",
      "fold 1\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's binary_logloss: 0.0404424\tvalid_1's binary_logloss: 0.0400415\n",
      "Early stopping, best iteration is:\n",
      "[223]\ttraining's binary_logloss: 0.0404424\tvalid_1's binary_logloss: 0.0400414\n",
      "fold 2\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's binary_logloss: 0.0402128\tvalid_1's binary_logloss: 0.0408632\n",
      "Early stopping, best iteration is:\n",
      "[294]\ttraining's binary_logloss: 0.0402128\tvalid_1's binary_logloss: 0.0408632\n",
      "fold 3\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's binary_logloss: 0.040134\tvalid_1's binary_logloss: 0.0412131\n",
      "Early stopping, best iteration is:\n",
      "[232]\ttraining's binary_logloss: 0.0401346\tvalid_1's binary_logloss: 0.0412129\n",
      "fold 4\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's binary_logloss: 0.0401768\tvalid_1's binary_logloss: 0.0410805\n",
      "Early stopping, best iteration is:\n",
      "[148]\ttraining's binary_logloss: 0.0401978\tvalid_1's binary_logloss: 0.0410793\n",
      "Final result: \n",
      "accuracy score: 0.986   recall: 0.692   precision: 0.847   AUC: 0.844  F1: 0.762\n"
     ]
    }
   ],
   "source": [
    "oof_lgb_e = KFold_lgb(df_e, param, ['country','new_user','source'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features = 5\n",
      "fold 0\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's binary_logloss: 0.0402937\tvalid_1's binary_logloss: 0.042195\n",
      "Early stopping, best iteration is:\n",
      "[304]\ttraining's binary_logloss: 0.0402937\tvalid_1's binary_logloss: 0.042195\n",
      "fold 1\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's binary_logloss: 0.0407849\tvalid_1's binary_logloss: 0.0402084\n",
      "Early stopping, best iteration is:\n",
      "[211]\ttraining's binary_logloss: 0.040785\tvalid_1's binary_logloss: 0.0402084\n",
      "fold 2\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's binary_logloss: 0.040623\tvalid_1's binary_logloss: 0.0408628\n",
      "Early stopping, best iteration is:\n",
      "[299]\ttraining's binary_logloss: 0.040623\tvalid_1's binary_logloss: 0.0408628\n",
      "fold 3\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's binary_logloss: 0.0405609\tvalid_1's binary_logloss: 0.0413371\n",
      "Early stopping, best iteration is:\n",
      "[186]\ttraining's binary_logloss: 0.0405637\tvalid_1's binary_logloss: 0.0413368\n",
      "fold 4\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's binary_logloss: 0.0405859\tvalid_1's binary_logloss: 0.0412074\n",
      "Early stopping, best iteration is:\n",
      "[263]\ttraining's binary_logloss: 0.0405859\tvalid_1's binary_logloss: 0.0412074\n",
      "Final result: \n",
      "accuracy score: 0.986   recall: 0.69   precision: 0.849   AUC: 0.843  F1: 0.761\n"
     ]
    }
   ],
   "source": [
    "oof_lgb_e_scaled = KFold_lgb(df_e_scaled, param, ['country','new_user','source'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning with optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial, num_folds=5, stratified=True, target='converted'):\n",
    "    \n",
    "    \"\"\"\n",
    "    gbdt is the most popular one\n",
    "    you usually only need gbdt or goss, dart rarely works and I haven't tried rf before\n",
    "    \"\"\"\n",
    "    \n",
    "    categorical_features = ['country','new_user','source']\n",
    "    if stratified:\n",
    "        folds = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=42)\n",
    "    else:\n",
    "        folds = KFold(n_splits= num_folds, shuffle=True, random_state=42)\n",
    "        \n",
    "    oof_preds = np.zeros(df_e.shape[0])\n",
    "    feats = [f for f in df_e.columns if f !=target]\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(df_e[feats], df_e[target])):\n",
    "        train_x, train_y = df_e[feats].iloc[train_idx], df_e[target].iloc[train_idx]\n",
    "        valid_x, valid_y = df_e[feats].iloc[valid_idx], df_e[target].iloc[valid_idx]\n",
    "\n",
    "        lgb_train = lgb.Dataset(train_x,\n",
    "                                label=train_y,\n",
    "                                categorical_feature=categorical_features)\n",
    "        lgb_test = lgb.Dataset(valid_x,\n",
    "                               label=valid_y,\n",
    "                               categorical_feature=categorical_features)\n",
    "        param = {'objective': 'binary', 'metric': 'binary', 'verbosity': -1, 'n_jobs': -1, \n",
    "                 #'boosting_type': trial.suggest_categorical('boosting_type', ['goss', 'gbdt','dart','rf']),\n",
    "                 'boosting_type':'gbdt','seed':42, 'feature_fraction_seed':42,\n",
    "                 'learning_rate': trial.suggest_uniform('learning_rate', 1e-2, 1e-1),\n",
    "                 'feature_fraction': trial.suggest_uniform('feature_fraction', 0.9, 1.),\n",
    "                 'num_leaves': trial.suggest_int('num_leaves', 20, 40),\n",
    "                 'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 30),\n",
    "                 'max_depth': trial.suggest_int('max_depth', 10,20),\n",
    "                 'reg_alpha': trial.suggest_uniform('reg_alpha', 0, 10),\n",
    "                 'reg_lambda': trial.suggest_uniform('reg_lambda', 0, 10),\n",
    "                 'subsample': trial.suggest_uniform('subsample', 0.9, 1.0),\n",
    "                 'min_child_weight': trial.suggest_int('min_child_weight', 1, 20),\n",
    "                 'min_split_gain': trial.suggest_int('min_split_gain', 0, 10),\n",
    "                }\n",
    "        \n",
    "        if param['boosting_type'] == 'dart':\n",
    "            param['drop_rate'] = trial.suggest_loguniform('drop_rate', 1e-8, 1.0)\n",
    "            param['skip_drop'] = trial.suggest_loguniform('skip_drop', 1e-8, 1.0)\n",
    "\n",
    "        elif param['boosting_type'] == 'goss':\n",
    "            param['top_rate'] = trial.suggest_uniform('top_rate', 0.0, 1.0)\n",
    "            param['other_rate'] = trial.suggest_uniform('other_rate', 0.0, 1.0 - param['top_rate'])\n",
    "            \n",
    "        else:\n",
    "            param['bagging_freq'] = trial.suggest_int('bagging_freq', 0, 10)\n",
    "            param['bagging_fraction'] = trial.suggest_uniform('bagging_fraction', 0.9, 1.0)\n",
    "            param['bagging_seed'] = 42\n",
    "    \n",
    "    \n",
    "        clf = lgb.train(param, lgb_train, 40000, valid_sets=[lgb_train, lgb_test],\n",
    "                        verbose_eval=10000, early_stopping_rounds=1000)\n",
    "            \n",
    "        oof_preds[valid_idx] = clf.predict(df_e.iloc[valid_idx][feats], num_iteration=clf.best_iteration)\n",
    "        \n",
    "        del clf, train_x, train_y, valid_x, valid_y, train_idx, valid_idx\n",
    "        gc.collect()\n",
    "    \n",
    "    return (-1) * (f1_score(df_e[target], oof_preds.round()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[221]\ttraining's binary_logloss: 0.0399785\tvalid_1's binary_logloss: 0.0420321\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[116]\ttraining's binary_logloss: 0.0404978\tvalid_1's binary_logloss: 0.0400385\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[116]\ttraining's binary_logloss: 0.0402943\tvalid_1's binary_logloss: 0.040779\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[123]\ttraining's binary_logloss: 0.0402264\tvalid_1's binary_logloss: 0.0411117\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[123]\ttraining's binary_logloss: 0.040224\tvalid_1's binary_logloss: 0.0409846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-02-08 09:42:21,302] Finished a trial resulted in value: -0.7633596027205009. Current best value is -0.7633596027205009 with parameters: {'learning_rate': 0.08130918703579237, 'feature_fraction': 0.9104236852257412, 'num_leaves': 28, 'min_data_in_leaf': 11, 'max_depth': 11, 'reg_alpha': 2.354741171111124, 'reg_lambda': 7.943330066914159, 'subsample': 0.993096184336284, 'min_child_weight': 2, 'min_split_gain': 1, 'bagging_freq': 8, 'bagging_fraction': 0.9725584934631921}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[141]\ttraining's binary_logloss: 0.0403146\tvalid_1's binary_logloss: 0.0421423\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[101]\ttraining's binary_logloss: 0.0408302\tvalid_1's binary_logloss: 0.0401736\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[452]\ttraining's binary_logloss: 0.0406347\tvalid_1's binary_logloss: 0.0408559\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[137]\ttraining's binary_logloss: 0.0405446\tvalid_1's binary_logloss: 0.0413067\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[120]\ttraining's binary_logloss: 0.0405792\tvalid_1's binary_logloss: 0.0410699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-02-08 09:43:15,940] Finished a trial resulted in value: -0.7621414294203446. Current best value is -0.7633596027205009 with parameters: {'learning_rate': 0.08130918703579237, 'feature_fraction': 0.9104236852257412, 'num_leaves': 28, 'min_data_in_leaf': 11, 'max_depth': 11, 'reg_alpha': 2.354741171111124, 'reg_lambda': 7.943330066914159, 'subsample': 0.993096184336284, 'min_child_weight': 2, 'min_split_gain': 1, 'bagging_freq': 8, 'bagging_fraction': 0.9725584934631921}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[132]\ttraining's binary_logloss: 0.0402852\tvalid_1's binary_logloss: 0.0422726\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[145]\ttraining's binary_logloss: 0.0407948\tvalid_1's binary_logloss: 0.0400613\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[134]\ttraining's binary_logloss: 0.0405983\tvalid_1's binary_logloss: 0.040857\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[176]\ttraining's binary_logloss: 0.0405167\tvalid_1's binary_logloss: 0.0412426\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[135]\ttraining's binary_logloss: 0.0405408\tvalid_1's binary_logloss: 0.0410362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-02-08 09:44:00,775] Finished a trial resulted in value: -0.7622804647392597. Current best value is -0.7633596027205009 with parameters: {'learning_rate': 0.08130918703579237, 'feature_fraction': 0.9104236852257412, 'num_leaves': 28, 'min_data_in_leaf': 11, 'max_depth': 11, 'reg_alpha': 2.354741171111124, 'reg_lambda': 7.943330066914159, 'subsample': 0.993096184336284, 'min_child_weight': 2, 'min_split_gain': 1, 'bagging_freq': 8, 'bagging_fraction': 0.9725584934631921}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[75]\ttraining's binary_logloss: 0.0406525\tvalid_1's binary_logloss: 0.0424194\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[76]\ttraining's binary_logloss: 0.0411096\tvalid_1's binary_logloss: 0.0401831\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[84]\ttraining's binary_logloss: 0.0409646\tvalid_1's binary_logloss: 0.041118\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[97]\ttraining's binary_logloss: 0.040894\tvalid_1's binary_logloss: 0.0416256\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[109]\ttraining's binary_logloss: 0.0408109\tvalid_1's binary_logloss: 0.0412516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-02-08 09:44:40,037] Finished a trial resulted in value: -0.7607991360691145. Current best value is -0.7633596027205009 with parameters: {'learning_rate': 0.08130918703579237, 'feature_fraction': 0.9104236852257412, 'num_leaves': 28, 'min_data_in_leaf': 11, 'max_depth': 11, 'reg_alpha': 2.354741171111124, 'reg_lambda': 7.943330066914159, 'subsample': 0.993096184336284, 'min_child_weight': 2, 'min_split_gain': 1, 'bagging_freq': 8, 'bagging_fraction': 0.9725584934631921}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[95]\ttraining's binary_logloss: 0.0403791\tvalid_1's binary_logloss: 0.0422178\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[86]\ttraining's binary_logloss: 0.0408438\tvalid_1's binary_logloss: 0.0401916\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[96]\ttraining's binary_logloss: 0.0406833\tvalid_1's binary_logloss: 0.0408937\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[88]\ttraining's binary_logloss: 0.0405958\tvalid_1's binary_logloss: 0.0412741\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[90]\ttraining's binary_logloss: 0.0406178\tvalid_1's binary_logloss: 0.041086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-02-08 09:45:18,304] Finished a trial resulted in value: -0.7628622117090479. Current best value is -0.7633596027205009 with parameters: {'learning_rate': 0.08130918703579237, 'feature_fraction': 0.9104236852257412, 'num_leaves': 28, 'min_data_in_leaf': 11, 'max_depth': 11, 'reg_alpha': 2.354741171111124, 'reg_lambda': 7.943330066914159, 'subsample': 0.993096184336284, 'min_child_weight': 2, 'min_split_gain': 1, 'bagging_freq': 8, 'bagging_fraction': 0.9725584934631921}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[84]\ttraining's binary_logloss: 0.0407025\tvalid_1's binary_logloss: 0.0424712\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[92]\ttraining's binary_logloss: 0.0411478\tvalid_1's binary_logloss: 0.0402774\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[81]\ttraining's binary_logloss: 0.0409925\tvalid_1's binary_logloss: 0.0410581\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[77]\ttraining's binary_logloss: 0.0408623\tvalid_1's binary_logloss: 0.0414658\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[78]\ttraining's binary_logloss: 0.0409158\tvalid_1's binary_logloss: 0.0411805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-02-08 09:45:55,146] Finished a trial resulted in value: -0.7620020429009193. Current best value is -0.7633596027205009 with parameters: {'learning_rate': 0.08130918703579237, 'feature_fraction': 0.9104236852257412, 'num_leaves': 28, 'min_data_in_leaf': 11, 'max_depth': 11, 'reg_alpha': 2.354741171111124, 'reg_lambda': 7.943330066914159, 'subsample': 0.993096184336284, 'min_child_weight': 2, 'min_split_gain': 1, 'bagging_freq': 8, 'bagging_fraction': 0.9725584934631921}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[166]\ttraining's binary_logloss: 0.039882\tvalid_1's binary_logloss: 0.0420411\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[236]\ttraining's binary_logloss: 0.0404035\tvalid_1's binary_logloss: 0.0399737\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[177]\ttraining's binary_logloss: 0.0401691\tvalid_1's binary_logloss: 0.0407264\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[173]\ttraining's binary_logloss: 0.0401089\tvalid_1's binary_logloss: 0.0410677\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[175]\ttraining's binary_logloss: 0.0401544\tvalid_1's binary_logloss: 0.0409527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-02-08 09:46:48,702] Finished a trial resulted in value: -0.7632699250956513. Current best value is -0.7633596027205009 with parameters: {'learning_rate': 0.08130918703579237, 'feature_fraction': 0.9104236852257412, 'num_leaves': 28, 'min_data_in_leaf': 11, 'max_depth': 11, 'reg_alpha': 2.354741171111124, 'reg_lambda': 7.943330066914159, 'subsample': 0.993096184336284, 'min_child_weight': 2, 'min_split_gain': 1, 'bagging_freq': 8, 'bagging_fraction': 0.9725584934631921}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[111]\ttraining's binary_logloss: 0.040462\tvalid_1's binary_logloss: 0.0422297\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[194]\ttraining's binary_logloss: 0.0409594\tvalid_1's binary_logloss: 0.0402165\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[154]\ttraining's binary_logloss: 0.0407609\tvalid_1's binary_logloss: 0.0409406\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[121]\ttraining's binary_logloss: 0.0406337\tvalid_1's binary_logloss: 0.0412349\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[110]\ttraining's binary_logloss: 0.0407014\tvalid_1's binary_logloss: 0.0411638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-02-08 09:47:27,649] Finished a trial resulted in value: -0.7629665535627727. Current best value is -0.7633596027205009 with parameters: {'learning_rate': 0.08130918703579237, 'feature_fraction': 0.9104236852257412, 'num_leaves': 28, 'min_data_in_leaf': 11, 'max_depth': 11, 'reg_alpha': 2.354741171111124, 'reg_lambda': 7.943330066914159, 'subsample': 0.993096184336284, 'min_child_weight': 2, 'min_split_gain': 1, 'bagging_freq': 8, 'bagging_fraction': 0.9725584934631921}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[263]\ttraining's binary_logloss: 0.0403568\tvalid_1's binary_logloss: 0.042179\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[253]\ttraining's binary_logloss: 0.0408717\tvalid_1's binary_logloss: 0.0400519\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[285]\ttraining's binary_logloss: 0.0406758\tvalid_1's binary_logloss: 0.0408621\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[246]\ttraining's binary_logloss: 0.0405745\tvalid_1's binary_logloss: 0.0412652\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[256]\ttraining's binary_logloss: 0.040612\tvalid_1's binary_logloss: 0.0410358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-02-08 09:48:25,170] Finished a trial resulted in value: -0.7626295336787564. Current best value is -0.7633596027205009 with parameters: {'learning_rate': 0.08130918703579237, 'feature_fraction': 0.9104236852257412, 'num_leaves': 28, 'min_data_in_leaf': 11, 'max_depth': 11, 'reg_alpha': 2.354741171111124, 'reg_lambda': 7.943330066914159, 'subsample': 0.993096184336284, 'min_child_weight': 2, 'min_split_gain': 1, 'bagging_freq': 8, 'bagging_fraction': 0.9725584934631921}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[231]\ttraining's binary_logloss: 0.0402829\tvalid_1's binary_logloss: 0.0421136\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[133]\ttraining's binary_logloss: 0.0408149\tvalid_1's binary_logloss: 0.0400822\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[133]\ttraining's binary_logloss: 0.0405704\tvalid_1's binary_logloss: 0.0408099\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[135]\ttraining's binary_logloss: 0.0404948\tvalid_1's binary_logloss: 0.0412262\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[214]\ttraining's binary_logloss: 0.0405162\tvalid_1's binary_logloss: 0.0409578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-02-08 09:49:13,838] Finished a trial resulted in value: -0.7629366106080206. Current best value is -0.7633596027205009 with parameters: {'learning_rate': 0.08130918703579237, 'feature_fraction': 0.9104236852257412, 'num_leaves': 28, 'min_data_in_leaf': 11, 'max_depth': 11, 'reg_alpha': 2.354741171111124, 'reg_lambda': 7.943330066914159, 'subsample': 0.993096184336284, 'min_child_weight': 2, 'min_split_gain': 1, 'bagging_freq': 8, 'bagging_fraction': 0.9725584934631921}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[792]\ttraining's binary_logloss: 0.0397462\tvalid_1's binary_logloss: 0.0420923\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[710]\ttraining's binary_logloss: 0.0403187\tvalid_1's binary_logloss: 0.0399554\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[753]\ttraining's binary_logloss: 0.0400793\tvalid_1's binary_logloss: 0.0407792\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[732]\ttraining's binary_logloss: 0.0400038\tvalid_1's binary_logloss: 0.0411474\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[666]\ttraining's binary_logloss: 0.0400945\tvalid_1's binary_logloss: 0.0409446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-02-08 09:52:20,101] Finished a trial resulted in value: -0.7631024990554325. Current best value is -0.7633596027205009 with parameters: {'learning_rate': 0.08130918703579237, 'feature_fraction': 0.9104236852257412, 'num_leaves': 28, 'min_data_in_leaf': 11, 'max_depth': 11, 'reg_alpha': 2.354741171111124, 'reg_lambda': 7.943330066914159, 'subsample': 0.993096184336284, 'min_child_weight': 2, 'min_split_gain': 1, 'bagging_freq': 8, 'bagging_fraction': 0.9725584934631921}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[181]\ttraining's binary_logloss: 0.0404481\tvalid_1's binary_logloss: 0.0423931\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[171]\ttraining's binary_logloss: 0.0409397\tvalid_1's binary_logloss: 0.0400779\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[170]\ttraining's binary_logloss: 0.0407509\tvalid_1's binary_logloss: 0.0408954\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[196]\ttraining's binary_logloss: 0.0406456\tvalid_1's binary_logloss: 0.0412914\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[168]\ttraining's binary_logloss: 0.0406916\tvalid_1's binary_logloss: 0.0410522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-02-08 09:53:10,760] Finished a trial resulted in value: -0.7629901696013828. Current best value is -0.7633596027205009 with parameters: {'learning_rate': 0.08130918703579237, 'feature_fraction': 0.9104236852257412, 'num_leaves': 28, 'min_data_in_leaf': 11, 'max_depth': 11, 'reg_alpha': 2.354741171111124, 'reg_lambda': 7.943330066914159, 'subsample': 0.993096184336284, 'min_child_weight': 2, 'min_split_gain': 1, 'bagging_freq': 8, 'bagging_fraction': 0.9725584934631921}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[321]\ttraining's binary_logloss: 0.0400535\tvalid_1's binary_logloss: 0.0420489\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[265]\ttraining's binary_logloss: 0.0405556\tvalid_1's binary_logloss: 0.039966\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[277]\ttraining's binary_logloss: 0.040357\tvalid_1's binary_logloss: 0.0407238\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[248]\ttraining's binary_logloss: 0.0402844\tvalid_1's binary_logloss: 0.0411242\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[254]\ttraining's binary_logloss: 0.0403129\tvalid_1's binary_logloss: 0.0409653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-02-08 09:53:53,233] Finished a trial resulted in value: -0.7630656383150854. Current best value is -0.7633596027205009 with parameters: {'learning_rate': 0.08130918703579237, 'feature_fraction': 0.9104236852257412, 'num_leaves': 28, 'min_data_in_leaf': 11, 'max_depth': 11, 'reg_alpha': 2.354741171111124, 'reg_lambda': 7.943330066914159, 'subsample': 0.993096184336284, 'min_child_weight': 2, 'min_split_gain': 1, 'bagging_freq': 8, 'bagging_fraction': 0.9725584934631921}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[119]\ttraining's binary_logloss: 0.040316\tvalid_1's binary_logloss: 0.0421349\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[112]\ttraining's binary_logloss: 0.0408449\tvalid_1's binary_logloss: 0.0400573\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[128]\ttraining's binary_logloss: 0.0406579\tvalid_1's binary_logloss: 0.0408502\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[111]\ttraining's binary_logloss: 0.0405414\tvalid_1's binary_logloss: 0.0411754\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[150]\ttraining's binary_logloss: 0.0405774\tvalid_1's binary_logloss: 0.0411005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-02-08 09:54:29,656] Finished a trial resulted in value: -0.7651409583020687. Current best value is -0.7651409583020687 with parameters: {'learning_rate': 0.07755148872608791, 'feature_fraction': 0.9535984461921252, 'num_leaves': 24, 'min_data_in_leaf': 13, 'max_depth': 17, 'reg_alpha': 6.742189622082368, 'reg_lambda': 9.800193440118033, 'subsample': 0.9987429090566036, 'min_child_weight': 1, 'min_split_gain': 2, 'bagging_freq': 9, 'bagging_fraction': 0.9227591042454988}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[258]\ttraining's binary_logloss: 0.0406737\tvalid_1's binary_logloss: 0.0424629\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[284]\ttraining's binary_logloss: 0.0411948\tvalid_1's binary_logloss: 0.0402267\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[270]\ttraining's binary_logloss: 0.0409476\tvalid_1's binary_logloss: 0.0410055\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[281]\ttraining's binary_logloss: 0.0408678\tvalid_1's binary_logloss: 0.0414406\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[258]\ttraining's binary_logloss: 0.040932\tvalid_1's binary_logloss: 0.0412004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-02-08 09:55:18,729] Finished a trial resulted in value: -0.7635207929325577. Current best value is -0.7651409583020687 with parameters: {'learning_rate': 0.07755148872608791, 'feature_fraction': 0.9535984461921252, 'num_leaves': 24, 'min_data_in_leaf': 13, 'max_depth': 17, 'reg_alpha': 6.742189622082368, 'reg_lambda': 9.800193440118033, 'subsample': 0.9987429090566036, 'min_child_weight': 1, 'min_split_gain': 2, 'bagging_freq': 9, 'bagging_fraction': 0.9227591042454988}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[129]\ttraining's binary_logloss: 0.0404424\tvalid_1's binary_logloss: 0.042275\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[125]\ttraining's binary_logloss: 0.0409159\tvalid_1's binary_logloss: 0.0400903\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[141]\ttraining's binary_logloss: 0.0407343\tvalid_1's binary_logloss: 0.0409122\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[136]\ttraining's binary_logloss: 0.0406493\tvalid_1's binary_logloss: 0.0412504\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[127]\ttraining's binary_logloss: 0.0406973\tvalid_1's binary_logloss: 0.0410569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-02-08 09:56:02,526] Finished a trial resulted in value: -0.7638066530304661. Current best value is -0.7651409583020687 with parameters: {'learning_rate': 0.07755148872608791, 'feature_fraction': 0.9535984461921252, 'num_leaves': 24, 'min_data_in_leaf': 13, 'max_depth': 17, 'reg_alpha': 6.742189622082368, 'reg_lambda': 9.800193440118033, 'subsample': 0.9987429090566036, 'min_child_weight': 1, 'min_split_gain': 2, 'bagging_freq': 9, 'bagging_fraction': 0.9227591042454988}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[140]\ttraining's binary_logloss: 0.0405905\tvalid_1's binary_logloss: 0.0423781\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[143]\ttraining's binary_logloss: 0.0411347\tvalid_1's binary_logloss: 0.0402666\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[135]\ttraining's binary_logloss: 0.0409179\tvalid_1's binary_logloss: 0.041042\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[155]\ttraining's binary_logloss: 0.040791\tvalid_1's binary_logloss: 0.0413599\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[142]\ttraining's binary_logloss: 0.0408816\tvalid_1's binary_logloss: 0.0411618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-02-08 09:56:51,750] Finished a trial resulted in value: -0.762854371025116. Current best value is -0.7651409583020687 with parameters: {'learning_rate': 0.07755148872608791, 'feature_fraction': 0.9535984461921252, 'num_leaves': 24, 'min_data_in_leaf': 13, 'max_depth': 17, 'reg_alpha': 6.742189622082368, 'reg_lambda': 9.800193440118033, 'subsample': 0.9987429090566036, 'min_child_weight': 1, 'min_split_gain': 2, 'bagging_freq': 9, 'bagging_fraction': 0.9227591042454988}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[130]\ttraining's binary_logloss: 0.0404155\tvalid_1's binary_logloss: 0.0422704\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[115]\ttraining's binary_logloss: 0.0409346\tvalid_1's binary_logloss: 0.0401774\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[124]\ttraining's binary_logloss: 0.0407117\tvalid_1's binary_logloss: 0.0408657\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[118]\ttraining's binary_logloss: 0.0406353\tvalid_1's binary_logloss: 0.0413032\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[124]\ttraining's binary_logloss: 0.040668\tvalid_1's binary_logloss: 0.0410457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-02-08 09:57:35,254] Finished a trial resulted in value: -0.7624082865774707. Current best value is -0.7651409583020687 with parameters: {'learning_rate': 0.07755148872608791, 'feature_fraction': 0.9535984461921252, 'num_leaves': 24, 'min_data_in_leaf': 13, 'max_depth': 17, 'reg_alpha': 6.742189622082368, 'reg_lambda': 9.800193440118033, 'subsample': 0.9987429090566036, 'min_child_weight': 1, 'min_split_gain': 2, 'bagging_freq': 9, 'bagging_fraction': 0.9227591042454988}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[135]\ttraining's binary_logloss: 0.0404133\tvalid_1's binary_logloss: 0.0421707\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[134]\ttraining's binary_logloss: 0.0408935\tvalid_1's binary_logloss: 0.0401465\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[125]\ttraining's binary_logloss: 0.0407399\tvalid_1's binary_logloss: 0.0409301\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[124]\ttraining's binary_logloss: 0.0406386\tvalid_1's binary_logloss: 0.0412529\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[151]\ttraining's binary_logloss: 0.0406533\tvalid_1's binary_logloss: 0.0410931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-02-08 09:58:19,277] Finished a trial resulted in value: -0.7631763122476447. Current best value is -0.7651409583020687 with parameters: {'learning_rate': 0.07755148872608791, 'feature_fraction': 0.9535984461921252, 'num_leaves': 24, 'min_data_in_leaf': 13, 'max_depth': 17, 'reg_alpha': 6.742189622082368, 'reg_lambda': 9.800193440118033, 'subsample': 0.9987429090566036, 'min_child_weight': 1, 'min_split_gain': 2, 'bagging_freq': 9, 'bagging_fraction': 0.9227591042454988}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[192]\ttraining's binary_logloss: 0.0398179\tvalid_1's binary_logloss: 0.0420492\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[232]\ttraining's binary_logloss: 0.0402654\tvalid_1's binary_logloss: 0.0400472\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[139]\ttraining's binary_logloss: 0.0402288\tvalid_1's binary_logloss: 0.0408383\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[144]\ttraining's binary_logloss: 0.0401049\tvalid_1's binary_logloss: 0.041164\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[119]\ttraining's binary_logloss: 0.0402185\tvalid_1's binary_logloss: 0.0410144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-02-08 09:59:48,709] Finished a trial resulted in value: -0.7621157274839268. Current best value is -0.7651409583020687 with parameters: {'learning_rate': 0.07755148872608791, 'feature_fraction': 0.9535984461921252, 'num_leaves': 24, 'min_data_in_leaf': 13, 'max_depth': 17, 'reg_alpha': 6.742189622082368, 'reg_lambda': 9.800193440118033, 'subsample': 0.9987429090566036, 'min_child_weight': 1, 'min_split_gain': 2, 'bagging_freq': 9, 'bagging_fraction': 0.9227591042454988}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "study.best_params: \t\n",
      "{'learning_rate': 0.07755148872608791, 'feature_fraction': 0.9535984461921252, 'num_leaves': 24, 'min_data_in_leaf': 13, 'max_depth': 17, 'reg_alpha': 6.742189622082368, 'reg_lambda': 9.800193440118033, 'subsample': 0.9987429090566036, 'min_child_weight': 1, 'min_split_gain': 2, 'bagging_freq': 9, 'bagging_fraction': 0.9227591042454988}\n",
      "study.best_value: \t\n",
      "-0.7651409583020687\n",
      "study.best_trial.user_attrs: \t\n",
      "{}\n",
      "CPU times: user 1h 23min 42s, sys: 7min 45s, total: 1h 31min 28s\n",
      "Wall time: 18min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=20)\n",
    "print('study.best_params: \\t')\n",
    "print(study.best_params)\n",
    "print('study.best_value: \\t')\n",
    "print(study.best_value)\n",
    "print('study.best_trial.user_attrs: \\t')\n",
    "print(study.best_trial.user_attrs)\n",
    "optuna_lgb = study.trials_dataframe()\n",
    "optuna_lgb.to_csv(\"magic.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features = 5\n",
      "fold 0\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's binary_logloss: 0.0403146\tvalid_1's binary_logloss: 0.0421362\n",
      "Early stopping, best iteration is:\n",
      "[119]\ttraining's binary_logloss: 0.040316\tvalid_1's binary_logloss: 0.0421349\n",
      "fold 1\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's binary_logloss: 0.0408449\tvalid_1's binary_logloss: 0.0400573\n",
      "Early stopping, best iteration is:\n",
      "[112]\ttraining's binary_logloss: 0.0408449\tvalid_1's binary_logloss: 0.0400573\n",
      "fold 2\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's binary_logloss: 0.0406579\tvalid_1's binary_logloss: 0.0408502\n",
      "Early stopping, best iteration is:\n",
      "[120]\ttraining's binary_logloss: 0.0406579\tvalid_1's binary_logloss: 0.0408502\n",
      "fold 3\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's binary_logloss: 0.0405376\tvalid_1's binary_logloss: 0.0411765\n",
      "Early stopping, best iteration is:\n",
      "[111]\ttraining's binary_logloss: 0.0405414\tvalid_1's binary_logloss: 0.0411754\n",
      "fold 4\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's binary_logloss: 0.0405774\tvalid_1's binary_logloss: 0.0411005\n",
      "Early stopping, best iteration is:\n",
      "[124]\ttraining's binary_logloss: 0.0405774\tvalid_1's binary_logloss: 0.0411005\n",
      "Final result: \n",
      "accuracy score: 0.986   recall: 0.7   precision: 0.844   AUC: 0.848  F1: 0.765\n"
     ]
    }
   ],
   "source": [
    "best_params = {**{'objective': 'binary', 'metric': 'binary', 'verbosity': -1, 'n_jobs': -1,\n",
    "                'boosting_type':'gbdt', 'seed':42, 'feature_fraction_seed':42, 'bagging_seed':42},\n",
    "               **study.best_params}\n",
    "\n",
    "oof_lgb_best = KFold_lgb(df_e, best_params, ['country','new_user','source'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features = 5\n",
      "fold 0\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's binary_logloss: 0.0404424\tvalid_1's binary_logloss: 0.042275\n",
      "Early stopping, best iteration is:\n",
      "[135]\ttraining's binary_logloss: 0.0404424\tvalid_1's binary_logloss: 0.042275\n",
      "fold 1\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's binary_logloss: 0.0409146\tvalid_1's binary_logloss: 0.0400903\n",
      "Early stopping, best iteration is:\n",
      "[125]\ttraining's binary_logloss: 0.0409159\tvalid_1's binary_logloss: 0.0400903\n",
      "fold 2\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's binary_logloss: 0.0407343\tvalid_1's binary_logloss: 0.0409122\n",
      "Early stopping, best iteration is:\n",
      "[125]\ttraining's binary_logloss: 0.0407343\tvalid_1's binary_logloss: 0.0409122\n",
      "fold 3\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's binary_logloss: 0.0406493\tvalid_1's binary_logloss: 0.0412504\n",
      "Early stopping, best iteration is:\n",
      "[124]\ttraining's binary_logloss: 0.0406493\tvalid_1's binary_logloss: 0.0412504\n",
      "fold 4\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's binary_logloss: 0.0406973\tvalid_1's binary_logloss: 0.0410569\n",
      "Early stopping, best iteration is:\n",
      "[133]\ttraining's binary_logloss: 0.0406973\tvalid_1's binary_logloss: 0.0410569\n",
      "Final result: \n",
      "accuracy score: 0.986   recall: 0.696   precision: 0.847   AUC: 0.846  F1: 0.764\n"
     ]
    }
   ],
   "source": [
    "best_params_1 = {**{'objective': 'binary', 'metric': 'binary', 'verbosity': -1, 'n_jobs': -1,\n",
    "                 'boosting_type':'gbdt', 'seed':42, 'feature_fraction_seed':42, 'bagging_seed':42},\n",
    "                 **study.trials_dataframe().sort_values(by='value')['params'].iloc[1,:].to_dict()}\n",
    "\n",
    "\n",
    "for key in ['max_depth','min_child_weight','min_data_in_leaf','min_split_gain','num_leaves','bagging_freq']:\n",
    "    best_params_1[key] = int(best_params_1[key])\n",
    "\n",
    "\n",
    "oof_lgb_best_1 = KFold_lgb(df_e, best_params_1, ['country','new_user','source'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking models sometimes give better results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.766606248000853"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(df_e['converted'], np.max([oof_lgb_best,oof_lgb_best_1],0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7678646050982031"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(df_e['converted'], np.max([oof_lgb_best,oof_lgb_best_1, *oof_list_e[:2]],0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.767915436032955"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(df_e['converted'], np.max([oof_lgb_best,oof_lgb_best_1, *oof_list_e[:2],*oof_list_e_scaled[:2]],0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The best stack score that I can get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7680033157185785"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(df_e['converted'], np.max([oof_lgb_best,oof_lgb_best_1, *oof_list_e[:2], *oof_list_e_scaled[:2],\n",
    "                                    *[oof_list_ohe[1]], *[oof_list_ohe[4]],],0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The KFold method to do model stacking\n",
    "    It works better for regression problems, not this time\n",
    "    The reason why np.max works better for stacking is because we have unbalanced dataset and this is a classification problem\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_features = np.column_stack([oof_lgb_best,oof_lgb_best_1, *oof_list_e[:2], *oof_list_e_scaled[:2],\n",
    "                                    *[oof_list_ohe[1]], *[oof_list_ohe[4]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KFold_stacking(oof_features, target, reg, n_splits=5):\n",
    "    # choose a different random_state!\n",
    "    folds = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=2020)\n",
    "    stacked_oof = np.zeros(len(target))\n",
    "    \n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(oof_features, target)):    \n",
    "        \n",
    "        x_trn, y_trn = oof_features[trn_idx,:], target[trn_idx]\n",
    "        x_val, y_val = oof_features[val_idx,:], target[val_idx]\n",
    "                \n",
    "        reg.fit(x_trn, y_trn)\n",
    "        \n",
    "        stacked_preds = reg.predict(x_val)\n",
    "        stacked_oof[val_idx] = stacked_preds.round()\n",
    "          \n",
    "    ACC = accuracy_score(target, stacked_oof).round(3)\n",
    "    REC = recall_score(target, stacked_oof).round(3)\n",
    "    PRE = precision_score(target, stacked_oof).round(3)\n",
    "    AUC = roc_auc_score(target, stacked_oof).round(3)\n",
    "    KAP = cohen_kappa_score(target, stacked_oof).round(3)\n",
    "    F1  = f1_score(target, stacked_oof).round(7)\n",
    "    \n",
    "    print(f'{ACC}\\t\\t{REC}\\t{PRE}\\t\\t{AUC}\\t{F1}')\n",
    "    return oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\tRecall\tPrecision\tAUC\tF1\n",
      "0.986\t\t0.693\t0.848\t\t0.845\t0.7630812\n",
      "0.986\t\t0.694\t0.849\t\t0.845\t0.7633382\n",
      "0.986\t\t0.694\t0.849\t\t0.845\t0.7633382\n",
      "0.986\t\t0.693\t0.849\t\t0.844\t0.7628454\n",
      "0.986\t\t0.7\t0.845\t\t0.848\t0.7658001\n",
      "0.986\t\t0.69\t0.851\t\t0.843\t0.7623119\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy\\tRecall\\tPrecision\\tAUC\\tF1')\n",
    "_ = KFold_stacking(oof_features, df_e['converted'], LinearRegression())\n",
    "_ = KFold_stacking(oof_features[:,:6], df_e['converted'], LinearRegression())\n",
    "_ = KFold_stacking(oof_features[:,:5], df_e['converted'], LinearRegression())\n",
    "_ = KFold_stacking(oof_features[:,:4], df_e['converted'], LinearRegression())\n",
    "_ = KFold_stacking(oof_features[:,:3], df_e['converted'], LinearRegression())\n",
    "_ = KFold_stacking(oof_features[:,:2], df_e['converted'], LinearRegression())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
